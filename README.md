# Weather Data DG

Web api built with FastApi, Postgres and Celery + Redis.  

## Dependencies:
Python 3.10 (3.10.14)  
Docker 20.10 + docker-compose 2.12

## Setup
### Run
1. clone this repo.  
2. cd into it and create `.env.docker-compose` file following sample.env.docker-compose variables.  
3. run `docker compose -f stack-docker-compose up --build`.

### Test coverage
1. clone this repo.  
2. cd into it and create `.env` file following sample.env variables.  
3. run `docker build -f Test.Dockerfile -t dg-test-leofernanndes .` to build test image.  
4. run `docker run --env-file .env dg-test-leofernanndes` to execute tests.

## Test API 
Once application is running with docker-compose, the service is exposed on http://localhost:18000 with an autogenerated swagger ui on /docs.  

#### Post to create a weather data request: Successful response 201
1. May be done by using the swagger interface.  

2. May be done using http clients such as postman with:  
url: http://localhost:18000/ 
payload: {"id": "unique_id"}

3. May be done through command line requests like curl:
`curl -H "Content-Type: application/json" -d '{"id": "unique_id"}' -X POST http://localhost:18000/`

#### Get request to check data retrieval status: Successful response 200
May be done using the same methods used to POST in addition to a simple browser request to http://localhost:18000/{id}

## Technical decisions
### Infrastructure
1. Celery is a very common tool to manage asynchronous tasks with python being recommended as standard solution by Django for example.  
2. The most common queue application used with Celery is Redis.  
3. The selected database, Postgres, also arise from the most common ones in terms of relational databases.  

Considering the simplicity of the project, both Redis and Postgres are easily exposed as backing services using standard docker images.  

### Framework
Fast api, as the name indicates, is a lightweight web framework created to easily come up with a decent service. It has become one of the top of mind python frameworks in recent years mainly replacing Flask and relies on an engaged community.  
The selected ORM, SqlAlchemy comes in pair with Alembic which is a recomended solution for migrations management.


### Open Weather API and Background tasks
The simplest way of covering the requirements is to set a periodic task to run once a second to check if there are uncompleted requests, get ordered uncompleted requests and retrieve the next city data from the city_id list. This way we avoid hitting the 60/minute request throttle limit.  
Altough this approach seems to better solve the problem. There may be a prefered method that may be applied with slighlty changes in the requirements:  
1. The idea of retrieving weather data for all the cities for each new request has an imediate problem of taking 3 minutes to request to be accomplished. Receiving 100 calls at the same time would take 4h30m to finish so the last user would have to wait all this long to receive an information we would already have downloaded 99 times.  
2. One of the limits weather api has are the 60/min requests, but they have another one which is 1 million requests a month which would be broken if we receive enough requests to keep the 1 call per second for 11 days letting our service out for the last 19 days of the month.
3. The weather data SLA for free accounts is 2h refresh rate so making requests to the same city in short intervals DOES NOT ASSURE an updated response.  

Considering this 3 topics, a better solution could be making a request to all of the cities every 10 minutes (to keep the most updated info as possible without breeaking the 1000000 requests por month limit) and let the responses in cache. Once a new request comes, we respond in no time as information is already in memory and save the current values in the database for the request. This approach would assure an instantaneous response for all requests also assuring we would never hit the free api usage limits. 